# Graph Density Analysis: 认知科学视角

> 问题：输入 token 与输出 node 的健康比例是什么？给定 node 数量，人类可理解的 edge 数量是多少？

## 1. 认知科学基础

### 1.1 Miller's Law (工作记忆容量)
- 人类工作记忆容量: **7 ± 2 chunks**
- 意味着：一次性呈现的概念数量不应超过 5-9 个
- 对于知识图谱：单个视图中的核心节点应控制在这个范围

### 1.2 Cognitive Load Theory (认知负荷理论)
- **内在负荷**: 材料本身的复杂性
- **外在负荷**: 呈现方式带来的负荷
- **相关负荷**: 有意义的学习处理

**启示**: 图谱应该减少外在负荷（噪声节点、无意义边），保留内在负荷（核心概念关系）

### 1.3 Network Comprehension Research

研究表明：
- **节点数**: 人类能有效理解的网络规模约 20-50 节点
- **边密度**: 超过平均度数 4-5 后，理解难度急剧上升
- **层次结构**: 分层网络比平面网络更易理解

## 2. 健康比例框架

### 2.1 Token-to-Node Ratio (输入压缩率)

```
压缩率 = Input Tokens / Output Nodes
```

| 压缩率 | 含义 | 适用场景 |
|--------|------|---------|
| < 100 tokens/node | 过度提取 | 可能有大量噪声 |
| 100-300 tokens/node | 细粒度 | 技术文档、教科书 |
| 300-800 tokens/node | 中等粒度 | 一般文档 |
| > 800 tokens/node | 粗粒度 | 概述、摘要 |

**建议**: 教科书/技术文档目标 **200-400 tokens/node**

### 2.2 Edge-to-Node Ratio (图密度)

```
密度系数 = Edges / Nodes
```

| 密度系数 | 图结构 | 人类理解性 |
|----------|--------|-----------|
| < 1.0 | 森林/树 | ✅ 易理解，但可能缺失关系 |
| 1.0-1.5 | 稀疏图 | ✅ 较易理解 |
| 1.5-2.5 | 中等密度 | ✅ 理想范围 |
| 2.5-4.0 | 较密图 | ⚠️ 需要分层/过滤 |
| > 4.0 | 密集图 | ❌ 信息过载 |

**建议**: 目标密度系数 **1.5-2.0**

### 2.3 Average Degree (平均度数)

```
平均度数 = 2 * Edges / Nodes
```

| 平均度数 | 理解难度 |
|----------|---------|
| 1-2 | 简单，接近树结构 |
| 2-3 | 理想，有适度连接 |
| 3-4 | 中等，需要认知努力 |
| > 4 | 困难，建议分层展示 |

## 3. 实际案例分析

### 3.1 threads-cv Ground Truth

- **文档**: ~5000 tokens (估计)
- **Nodes**: 17
- **Edges**: 15

计算：
- 压缩率: 5000/17 ≈ **294 tokens/node** ✅
- 密度系数: 15/17 ≈ **0.88** (略低)
- 平均度数: 2*15/17 ≈ **1.76** ✅

### 3.2 当前 Enhanced Pipeline 输出

- **threads-cv_enhanced.json**: 5 nodes, 0 edges
  - 压缩率: 5000/5 ≈ 1000 tokens/node ❌ 过于稀疏
  - 密度系数: 0 ❌ 完全没有连接

## 4. 推荐指标

### 4.1 针对教科书章节 (~3000-8000 tokens)

| 指标 | 最小值 | 理想值 | 最大值 |
|------|--------|--------|--------|
| Nodes | 8 | 15-25 | 40 |
| Edges | 8 | 20-35 | 60 |
| 压缩率 | 100 | 200-400 | 800 |
| 密度系数 | 0.8 | 1.5-2.0 | 3.0 |
| 平均度数 | 1.5 | 2.5-3.5 | 5.0 |

### 4.2 针对研究论文 (~8000-15000 tokens)

| 指标 | 最小值 | 理想值 | 最大值 |
|------|--------|--------|--------|
| Nodes | 15 | 25-40 | 60 |
| Edges | 15 | 35-60 | 100 |
| 压缩率 | 150 | 300-500 | 1000 |
| 密度系数 | 0.8 | 1.5-2.0 | 3.0 |

## 5. 质量检查清单

Pipeline 输出应该通过以下检查：

- [ ] **Node 数量合理**: 符合压缩率指标
- [ ] **Edge 数量 > 0**: 绝对不能为 0
- [ ] **无孤立节点**: 每个节点至少有 1 条边
- [ ] **无重复节点**: 同一概念不应出现多次
- [ ] **核心概念覆盖**: 文档标题/主题应该有对应节点
- [ ] **密度合理**: 密度系数在 1.0-2.5 范围内

## 6. 当前 Pipeline 问题诊断

基于这个框架，当前 Enhanced Pipeline 的问题：

1. **Edge = 0**: 完全失败，需要调查 RelationExtractor
2. **Node 数量过少**: 5 nodes for ~5000 tokens = 1000 tokens/node
3. **重复节点**: "Condition Variable" 出现两次
4. **核心概念缺失**: wait(), Lock, Producer/Consumer 都没有

**根因假设**:
- Grounding Verification 可能过度过滤了
- Relation Extraction 可能在验证后才运行，但此时实体已被过滤
- Entity deduplication 没有正常工作

---

*下一步: 调试 Pipeline 执行流程，特别是 Grounding Verification 的过滤行为*
