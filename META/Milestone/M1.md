# Milestone 1: MVP Core Pipeline

- **Status**: Active
- **Target Date**: 2026-02-21
- **Owner**: Team

## Goal

Build and validate the core knowledge extraction pipeline: PDF processing, chunking, entity/relation extraction, and graph construction. Focus on testing and validating the Node/Edge schema design and AI workflow before any frontend work.

## Scope

### In Scope
- PDF parsing and markdown conversion
- Recursive chunking with semantic boundary respect
- Entity Extractor Agent
- Relation Extractor Agent
- Validator Agent
- Entity Registry for cross-chunk resolution
- Output as JSON knowledge graph

### Out of Scope
- Frontend visualization (deferred)
- Multi-document synthesis (M2)
- User-facing features (spaced repetition, quizzes)
- Database persistence (JSON files for MVP)

## Deliverables

| Deliverable | Description | Acceptance Criteria |
|-------------|-------------|---------------------|
| PDF Parser | Convert PDF to structured markdown | Correctly parse 3 test PDFs with headers/paragraphs preserved |
| Chunker | Split documents into 512-token chunks | 15% overlap, respects paragraph boundaries |
| Entity Extractor | Extract entities per chunk | >70% accuracy on test documents |
| Relation Extractor | Identify entity relationships | >60% accuracy, correct type assignment |
| Entity Resolver | Merge duplicate entities across chunks | <10% false duplicates in final output |
| Validator | Verify extraction quality | Flag low-confidence results for review |

## Tasks

### Week 1: Infrastructure
- [ ] Set up Python project structure (`/src/pipeline/`, `/src/agents/`, etc.)
- [ ] Implement PDF parsing module (PyMuPDF)
- [ ] Implement recursive chunking module
- [ ] Create basic prompt templates

### Week 2: Core Agents
- [ ] Implement Entity Extractor Agent
- [ ] Implement Relation Extractor Agent
- [ ] Create Entity Registry
- [ ] Wire up basic pipeline flow

### Week 3: Validation & Testing
- [ ] Implement Validator Agent
- [ ] Add post-processing entity resolution
- [ ] Test with 3 different document types
- [ ] Tune prompts based on results
- [ ] Document quality metrics

## Dependencies

- Anthropic API access (Claude 3.5 Sonnet)
- Test documents (at least 3 varied types)

## Test Plan

1. **Unit Tests**: Each module (chunker, parser) tested independently
2. **Integration Test**: End-to-end pipeline on single document
3. **Quality Evaluation**:
   - Entity extraction precision/recall on annotated samples
   - Relation type accuracy assessment
   - Cross-chunk entity resolution accuracy

## Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| LLM output inconsistency | Medium | High | Implement retries with stricter prompts |
| Schema doesn't cover all relation types | Medium | Medium | Use RelatedTo as fallback, iterate schema |
| Cross-chunk resolution failures | Medium | Medium | Increase chunk overlap, add LLM verification |

## Notes

- This milestone focuses on **validation of core design** (Node/Edge schema, AI workflow)
- Frontend work is explicitly deferred until core logic is proven
- Keep detailed notes on prompt iterations for future reference
